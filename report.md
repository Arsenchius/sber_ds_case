## Отчет к заданию

Весь процесс состоит из нескольких этапов:

-Обработка данных

-Создание новых признаков (Этот пункт я откинул)

-Подбор гиперпараметров модели

-Итог

#### 1. Обработка данных
В данном процессе я использовал следующие техники:
- очистка данных от странных пробелов или символов, также знаков препинания и т.д.
- удаление стоп слов
- лемматизация

Код для обработки данных находится в файле
```
./src/data/preprocessing.py
./src/data/preprocessing.sh
```
Чтобы запустить предобработку данных, достаточно запустить файл preprocessing.sh и передать ему в качестве аргументов исполняемый файл и  размер батча для обработки(chunksize):
```
sh preprocessing.sh preprocessing.py 50000
```
Путем распараллеливания процесов, исходные данны проходят через все этапы предварительной обработки о которых описано выше.
#### 2. Создание новых признаков

В качестве новых признаков сначала я добавил две колонки: title_len и text_len. Однако далее в ходе обучения, степень важности этих признаков была очень мала по сравнению с текстовыми эмбедингами и я решил их откинуть.

#### 3. Построение эмбедингов

В качестве модели для построения эмбедингов я выбрал word2vec модель. Использовал следующие параметры для модели:
```
vector_size = 100
window=5
min_count=3
skipgram
```
Был вариант попробовать fasttext, но времени у меня было не так много :(

#### 4. Подбор гиперпараметров модели
Всего я обучил несколько различных моделей:
Logistic Regression, Random Forest, Nayive Bayes, SVM, KNN, NN, LightGBM, CatBoost. Все эти модели использовали текстовые эмбединги полученные с помощью word2vec модели.
Также еще я добавил обучени CatBoost модели с использованием встроенного обработчика текстовых данных.

Для подбора гиперпараметров модели я использовал framework Optuna. Я провел несколько экспериментов, по подбору гиперпараметров для таких моделей как: KNN, LightGBM, CatBoost.


#### 5. Итог
В целом базовые модели(p.s. для них я не проводил подбор гиперпараметров) показали неплохое качество:
```
precision = 0.92
recall = 0.92
f1 = 0.92
accuracy = 0.92
```
Хочу заметить, что SVM показал результаты лучше чем все остальные из базовых моделек.Однако он довольно долго обучается, так как GPU я не сразу раздобыл, поэтому эту модель я не стал дальше использовать для дальнейшего fine tuning-а.

Повторюсь к сожалению я не сразу смог раздобыть GPU, поэтому первоначальные эксперименты проводились не с лучшей скоростью, однако для нескольких последних экспериментов мне удалось раздобыть GPU, и провести их относительно
быстро.
Для KNN модели после подбора гиперпараметров результаты получились следующие:
```
precision = 0.93
recall = 0.93
f1 = 0.93
accuracy = 0.93
roc_auc(ovr)=0.9923
roc_auc(ovo)=0.9919
```
Для LightGBM + Word2Vec результаты получились следующие:
```
precision = 0.93
recall = 0.93
f1 = 0.93
accuracy = 0.93
roc_auc(ovr)=0.9944
roc_auc(ovo)=0.9940
```
В целом LightGBM не супер лучше чем KNN, однако в среднем ROC-AUC по всем подходам(one-vs-rest, one-vs-one) чуть больше.
Для модели CatBoost + Word2Vec:
```
precision = 0.93
recall = 0.93
f1 = 0.93
accuracy = 0.93
roc_auc(ovr)=0.9951
roc_auc(ovo)=0.9949
```
Видно,что тут у нас значения метрик не сильно лучше чем у предыдущих враиаций, однако ROC-AUC чуть лучше чем у предыдущих.
Во всех полученных моделях я смотрел на различные метрики качества.
Один из лучших результатов показала модель CatBoost+Word2Vec и просто CatBoost.
Лучшее качество удалось выбить с помощью обычной CatBoost модели без использования word2vec эмбедингов.
```
precision = 0.94
recall = 0.94
f1 = 0.94
accuracy = 0.94
roc_auc(ovr)=0.9955
roc_auc(ovo)=0.9953
```
Видим, что удалось повысить значения всех метрик относительно предыдущих подходов.
На мой взгляд это свзяано с тем, что под капотом catboost использует другой обработчик текстовых данных, отличный от word2vec. Внутри catboost используется - токенизация, стемминг + получение bag-of-words. Скорее именно это представление получилось более информативным нежели полученные с помощью word2vec эмбединги.

В конечном итоге я сохранил полученную в конце модель catboost, без использования word2vec эмбедингов.

#### 6. Дальнейшие улучшения

1) Попробовать большее кол-во итераций для подбора гиперпараметров в модели catboost + word2vec и lightgbm + word2vec, да и для обычного catboost тоже. Тут опять же повторюсь GPU раздобыл не сразу, поэтому кол-во итераций для подбора гиперпараметров было относительно небольшим + так как внутри функций(objective) используется 5 ступенчатая кросс валидация, времени на прогон одного набора гиперпараметров уходит еще больше.

2) Рассмотреть tf-idf вместо word2vec, так как встроенный обработчик внутри catboost модели использует bag-of-words имеет смысл попробовать использовать эмбединги полученные с помозью tf-idf подхода.

3) Также рассмотреть fasttex в качестве альтарниты для word2vec модели. Почему стоит это сделать?
Потому что word2vec представляет каждое слово в виде вектора, в то время как fasttext представляет каждое слово в виде набора n-граммов символов(то есть берет подслово). Это в какой-то степени позволяет охватить больше морфологической информации и лучше обработать текст. Также fasttext лучше справляется с довольно редкими словами.Однако тут есть нюанс с тем, что fasttext потребует большее кол-во памяти, но с этим проблем нет.

4) Использовать LSTM или Transformer в качестве альтернативных моделей для нашей задачи.
